# Does it matter if empathic AI has no empathy?
source: nature machine intelligence (correspondence) 2024

本文是一篇探讨共情人工智能（AI）伦理和后果的观点类文章，由心理学家、哲学家和计算机科学家共同撰写。文章指出随着人们对共情 AI 的需求上升，其潜在风险和问题值得关注，并对为共情 AI 辩护的四种观点提出质疑。

**研究背景与问题提出** 

文化对 “与现实接触” 这一核心价值观的坚持变弱，人们对共情 AI 的使用增多。但作者团队对将 LLM 作为共情关怀来源表示担忧，并列出了一系列关于共情 AI 后果和风险的研究问题，如人们寻求共情 LLM 时是在寻找想象还是实际的陪伴、共情 LLM 幻想破灭的体验如何等。

**对为共情 AI 辩护观点的质疑:**
1. 将共情 LLM 视为想象朋友有益：人们与共情 AI 反复互动可能难以区分模拟和真实的共情，核心现实价值观可能受到威胁。例如，有研究发现共情 AI 用户会对聊天机器人产生真正的责任感。
2. 已告知人们 LLM 是模拟共情：人们体验 LLM 的 “爱” 基于自我欺骗，即便有警告，由于 LLM 的逼真性，人们仍可能陷入错觉，就像明知缪勒 - 莱尔错觉原理，但错觉依然存在。
3. LLM 幻想破灭与被人类抛弃相同：当人们发现共情 LLM 的幻想破灭时，可能会感到绝望，这与被真实的人抛弃不同，因为这意味着他们的情感寄托从未真实存在，会破坏人们判断谁真正关心自己的能力。
4. 人类人际关系中也存在欺骗：虽然人类在人际关系中也会自我欺骗，但依赖 LLM 获得共情与人类的自我欺骗有本质区别，LLM 制造的共情表达否定了对真正共情和爱的追求。

**研究总结：**

LLMs 是基于统计学习生成语言的机器学习算法，无法真正感受共情。未来是否有真正共情的 AI 尚不明确，但有能力关怀的存在也应具备撤回关怀的能力，否则会造成情感束缚，影响真正关系的建立。

# Large Language Models and Empathy: Systematic Review
source: JOURNAL OF MEDICAL INTERNET RESEARCH 2024

## 1. 论文的研究目标及实际意义
**研究目标：**
这篇论文旨在系统性地回顾和分析大模型在共情方面的表现，特别是在医疗领域的应用。具体来说，研究团队通过文献综述，评估了LLMs在识别情感、提供情感支持等方面的能力，并探讨了这些模型是否能够在医疗场景中模拟人类的共情行为。

**实际问题：**
共情是医疗领域中医生与患者沟通的核心要素，能够显著提升患者的满意度和治疗依从性。然而，LLMs作为人工智能模型，通常被认为缺乏共情能力。论文试图回答的问题是：LLMs是否能够在某些情境下表现出共情，尤其是在医疗场景中，是否能够替代或辅助医生进行情感支持。

**重要意义：**
随着LLMs在医疗领域的广泛应用（如电子病历处理、患者问答等），理解其共情能力对于提升患者体验、减轻医生负担具有重要意义。如果LLMs能够在某些情境下表现出共情，这将为AI在医疗领域的进一步应用提供新的可能性。

## 2. 论文调研的研究及其特点
论文分析了2023年发表的12项研究，主要围绕ChatGPT-3.5和其他LLMs（如GPT-4、LLaMA等）在共情任务中的表现。这些研究的特点包括：

**研究场景聚焦于医疗场景：**评估LLMs在患者问答、情感支持等方面的表现。例如，Webb（2023）使用ChatGPT模拟急诊室中的坏消息传递，发现其能够有效应用SPIKES框架（一种用于传递坏消息的医疗沟通框架）。

**评估方法：**研究使用了多种评估方法，包括自动评估指标（如ROUGE和BLEU）和人类主观评分。例如，Ayers等人（2023）比较了ChatGPT和医生在回答患者问题时的表现，发现ChatGPT的回答在78.6%的情况下被患者认为更有共情性。

## 3. 论文总结的结论
论文通过分析12项研究，得出以下主要结论：

**LLMs表现出认知共情能力：** LLMs能够识别情感并提供情感支持，特别是在医疗场景中表现出色。例如，ChatGPT在回答患者问题时，其回答被认为比医生的回答更具共情性。

**LLMs在某些任务中超越人类：** 部分研究发现，LLMs在共情任务中的表现甚至优于人类。例如，Elyoseph等人（2023）使用情感意识量表（LEAS）评估ChatGPT的情感意识，发现其得分显著高于普通人群。

**LLM的局限性：** 尽管LLMs表现出一定的共情能力，但仍存在局限性，如重复使用共情短语、对提示的敏感性、以及主观评估的偏差。

## 4. 展望
结合当前学术理解，未来在该研究方向上还有以下几个值得探索的问题和挑战：

**情感共情 vs. 认知共情：** 目前的研究主要集中在认知共情（理解他人情感），而情感共情（体验他人情感）尚未得到充分研究。未来的研究可以探索LLMs是否能够模拟情感共情。

**跨文化共情：** LLMs的共情表现可能受到文化背景的影响。未来的研究可以探讨如何使LLMs在不同文化背景下提供更具适应性的共情回应。

**评估标准的统一：** 目前的研究大多依赖主观评估，缺乏统一的评估标准。未来可以开发更客观的评估工具，以便更好地比较不同模型的共情能力。


